---
title: Chapter 15. Design Google Drive
sidebar_position: 15
---

Правим дизайн за Google Drive, Dropbox, Drive on cloud продукт. Идеята е да изградим продукт, който потребителите могат да използват като място за съхранение на техните документи, да имат достъп до тях от различни устройства, да могат да си споделят с техни близки и познати.

Имаме следните изисквания:

- Трябва да предоставим качването на файлове от всякакъв вид с максимален размер от 10GB
- Трябва да криптираме всички файлове, които се качват с цел сигурност
- Всички промени по файловете тряба да се синхронизират възможно най-бързо, като при промяна на определен файл трябва да известим заинтересованите потребители
- Трябва да поддържаме 10М daily active users
- Трябва да покриваме всички стандарти за consistency, availability, scalability, etc. Общо взето трябва да имаме в предвид, че изграждаме една система, която ще е под голямо напрежение и ще бъде важна за много хора.
- Back of the Envelope анализ
  - Да предположим, че всеки потребител ще качва по два файла всеки ден, всеки от който е по 500KB
  - QPS = 10M \* 2 / 24 / 3600 = 232, закръгляме на **240**
  - Peak QPS = **480**
  - Всеки ден ще използваме 10М _ 2 _ 500 = 9.3TB, закръгляме на **10TB** пространство
  - Ако предположим, че след MVP-то ще получим 50М нови потребители и на всеки от тях дадем free trial от 10GB, то тогава трябва да сме готови да предоставим 50M \* 10 = 477PB, закръгляме на **500PB**
  - Заключението е че говорим за една система, която бързо може да излезе извън контрол при неправилно планиране

Започваме с high level design-a. Поради някаква причина авторът ни връща, може би носталгично, към първа глава и решава, че ще започнем възможно най-наивно и продукта ни ще се състои от един сървър с база данни и storage система, в която ще си пазим файловете на потребителите. Очевидно този подход не би проработил, освен ако продукта няма да си използва от само близки и приятели. До този извод ни води и авторът, като първото нещо, което прави е да отдели storage системата и да съзададе, дедикирани сървърни за съхранение на файлове, като ако ние сами си управляваме сървърите те биха били дистрибутирани и биха се управлявали на база consistent hashing, най-вероятно по namespace. От този подход също се отказваме поради простата причина, че дори някои от най-големите компании в света не намират за рентабилно сами да си управляват storage нуждите, а се въползват от cloud solution-и, като AWS S3. И ние ще се възползваме от тази услуга. S3 автоматично се занимава със скалиране и репликиране на данните, дори в отделни региони. След като изчистихме този проблем е удачно и вече да отделим базата за метаданните и да я скалираме при нужда и също така да дистрибутираме Web Server-a и да установим Load Balancer. Мисля, че е удачно вече да разгледаме истинският high level design по компоненти като ще добавим някои, които все още не сме споменавали:

- Клиент - Това ще е мобилното устройство или браузъра
- Load Balancers - Най-вероятно ще ни трябват и за Web Server-ите и за Block Server-ите, които сега ще обсъдим.
- Block Servers - Това ще са дедикирани сървъри, които ще се занимават с обработката на файловете и тяхното качване в S3. Нарича се block server, защото тук ще получаваме целите файлове, но ще ги разделяме на чънкове или блокове за да се съхраняват по-ефективно, всеки блок ще е по не повече от 4МВ.
- Cloud Storage - В нашият случай, ние ще използваме S3. Това е място за съхранение на файловете в облака по блокове.
- Cold Storage - Този тип място за съхранени е по-неефективен, но по-евтин и следователно тук можем да складираме stale файлове или такива файлове, които не се използват често, с цел да освободим място от основният сторидж.
- Web Servers - Това ще основата ни, тук ще изпълняваме аутентикация, ауторизация, ще се извършват действия свързани с мениджмънта на потребители, ще се свързваме с базата данни и кеша, най-вероятно ще изпращаме съобщения чрез message queue-та
- Database - Това ни базата данни, където ще пазим метадата за файловете, версиите на файловете, блоковете, ще пазим информация за потребитилите и логин данните им, устройствата им и т.н. В нашият случай бихме използвали релационна база данни, данните ни биха били нормализирани, плюс това релационните бази данни притежата ACID свойствата, които ни биха били полезни за изискванията.
- Cache - Тук ще пазим често изпозползвани данни с цел по-бърза обработка
- Notification Service - Ще ни трябва за да се справяме с известията, които трябва да изпращаме на потребителите при промяна на някои файл, който ги интересува.
- Offline Support Queue - В това queue ще пазим всички известия, които не са успяли да стигнат до потребителите, в случай, че те са офлайн. При установена връзка ще ги изветяваме.

Нека да изясним някои детайли и оптимизации, които трябва да имаме в предвид:

- Block Servers - Споменахме, че тук ще разделяме файловете на чънкове, но не казахме как това ни помага. Трябва да имаме отделни блокове за да можем да имплементираме механизъм наречен delta synchronization, чрез метод на синхронизация ъпдейтваме саме блоковете от файла, които са променении. Другото нещо, което трябва да споменем, е че всеки блок трябва да се криптира и компресира. Различните видове файлове имат нужда от различни видове компресиращи алгоритми, например за текст бихме използваме gzip.
- Notification Service - В главата за чат апликацията трябваше да избираме метод на комуникация между клиента и сървъра, като едни от опциите ни бяха log polling & web sockets, тогава избрахме WS поради факта, че имахме нужда от stateful, двупосочна връзка в реално време, тук пак имаме опцията да избираме между тези два метода, но long polling e много по-подходящ. Защо? Защото нямаме двупосочна връзка, тоест клиента се интересува от промени във файла за да може да реагира и да изтегли ъпдейтите, но сървъра няма нужда от клиента, който слуша.

Вече като имаме ясна представа за това как изглежда системата ни можем да направим примерен флоу. За качването на файлове:

1. Клиента изпраща започва два процеса едновременно:
   1. Изпраща заявка към web server-a, с метадата да му каже, че започва качването на файл
      1. Заявката минава през load balancer и стига до сървъра
      2. Сървъра записва метадатата като статуса на ъплоуда е пендинг
      3. Комуникира на notification service-a, чрез message queue, че процеса на качване на файл е започнал
      4. Notification service-а известява заинтересованите клиенти
   2. Изпраща заявка към Block server-a, с файла, за да започне качването му
      1. Заявката минава през load balancer и стига до сървъра
      2. Сървъра започва процеса на chunk-ване, компресиране и енкриптиране
      3. Блоковете се качват в cloud storage-a
      4. Статуса се сменя и се потвтарят стъпките свързани с известяването на заинтересованите потребители

За тегленето на файлове. Реално погледнато това е автоматизиран процес, който се задейства след промяната или качването на даден файл. Ако клиента е онлайн, той получава известие, че има нови промени по файла и е длъжен да ги изтегли. Ако клиента е офлайн, известията се запазват в кеш, в момента на установяване на връзка те се синхронизират.

Последно можем да споменем как се справяме с failure-и, но като цяло имаме доста generic подходи, нищо ново, ревюто стана вече доста дълго и при мен вече е доста късно така че си позволя да ги скипна.

А последна оптимизация би била да се оттървем от block server-ите и качването на файлове да се случва директно от клиента, но тука вече трябва да помислим много добре за проблеми със сигурността и други естествено.

Тва е, край на мача, дузпа за Аржентина, за мен беше чест. Доста добра книга много неща научих, много неща забравих след като ги научих, reread is a must.
